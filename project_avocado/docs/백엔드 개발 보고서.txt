백엔드 개발 보고서
**문서 목적**: 본 문서는 '아보카도' 프로젝트의 백엔드 시스템 개발 내용에 대한 기술적인 설명과 구현 결과를 공유하기 위해 작성되었습니다. 프론트엔드 및 AI 파트와의 원활한 협업과 시스템에 대한 이해를 돕는 것을 목표로 합니다.

## 1. 개요

### 1.1. 백엔드의 역할과 책임

아보카도 프로젝트의 백엔드 시스템은 **Node.js(Express)** 기반의 **API 서버**입니다. 사용자의 요청을 받아 비즈니스 로직을 처리하고, 데이터베이스와 상호작용하며, AI 모델 서버와 통신하는 중추적인 역할을 담당합니다.

- **주요 책임**:
    - 사용자 인증 및 회원 관리 기능 제공
    - TTS(텍스트-음성 변환) 요청 처리 및 AI 서버 중개
    - 커스텀 음성 모델 생성을 위한 파일 업로드 처리
    - 사용자별 음성 변환 기록 관리
    - 프론트엔드에 필요한 모든 데이터를 RESTful API 형태로 제공

### 1.2. 전체 시스템 아키텍처

본 프로젝트는 3-Tier 아키텍처를 기반으로 하며, 각 컴포넌트는 다음과 같이 상호작용합니다.

1. **Frontend (React)**: 사용자와의 인터페이스를 담당하며, 모든 요청은 백엔드 API를 통해 이루어집니다.
2. **Backend (Node.js)**: API 요청을 받아 핵심 로직을 처리하고, 필요에 따라 데이터베이스에 데이터를 저장/조회하거나 AI 서버에 특정 작업을 요청합니다.
3. **AI Model (Python)**: 백엔드로부터 텍스트와 음성 파일을 받아, 실제 음성 합성 및 스피커 임베딩 추출을 수행합니다.
4. **Database (MySQL)**: 사용자 정보, 변환 기록 등 모든 정적 데이터를 영구적으로 저장합니다.

## 2. 백엔드 시스템 상세 설계

### 2.1. 기술 스택

| 구분 | 기술 | 선정 사유 |
| --- | --- | --- |
| **런타임/프레임워크** | Node.js (Express) | 비동기 I/O 처리 모델을 통해 다수의 API 요청을 효율적으로 처리. 방대한 npm 생태계. |
| **데이터베이스** | MySQL | 정형화된 데이터를 안정적으로 관리하기 위한 관계형 데이터베이스. |
| **인증 방식** | JWT (JSON Web Token) | 세션 기반 인증보다 확장성이 뛰어나며, 토큰 기반으로 API 요청을 안전하게 인증. |
| **라이브러리** | `axios`, `bcrypt`, `multer`, `mysql2` | 외부 API 통신, 비밀번호 암호화, 파일 업로드, DB 비동기 처리 등을 위함. |

### 2.2. 디렉토리 구조

개발된 백엔드 서버의 전체 디렉토리 구조는 다음과 같습니다.

- **`src/config`**: 데이터베이스 연결 설정 등 환경 설정 파일을 관리합니다.
- **`src/middleware`**: JWT 토큰을 검증하는 인증 미들웨어 등 주요 미들웨어를 관리합니다.
- **`src/routes`**: 기능별(사용자, TTS, 모델, 기록) API 엔드포인트를 정의하고 라우팅 로직을 관리합니다.
- **`uploads/`**: 사용자가 커스텀 모델 생성을 위해 업로드한 음성 파일이 임시 저장되는 공간입니다.

### 2.3. 데이터베이스 설계 (ERD)

| User (사용자) | OutputVoice (변환 기록) | VoiceModel (음성 모델) |
| --- | --- | --- |
| `id` (PK) | `id` (PK) | `id` (PK) |
| `email` (UNIQUE) | `userId` (FK) | `userId` (FK) |
| `pw` | `modelId` (FK) | `type` |
| `name` | `text` | `name` |
| `age`, `gender` | `fileUrl` | `embedding_vector` |
| `createdAt` | `createdAt` |  |
- **관계**:
    - `User`와 `OutputVoice`는 1:N 관계 (한 명의 사용자는 여러 변환 기록을 가짐)
    - `User`와 `VoiceModel`은 1:1 관계 (한 명의 사용자는 하나의 커스텀 모델을 가짐)

## 3. API 명세 및 핵심 구현 내용

### 3.1. 인증 (Authentication)

모든 주요 API는 **JWT 기반의 토큰 인증**을 거칩니다.

- **프로세스**:
    1. 사용자가 `/api/users/login`으로 로그인을 성공하면, 서버는 JWT 토큰을 발급합니다.
    2. 프론트엔드는 발급받은 토큰을 저장하고, 이후 API 요청 시 `Authorization` 헤더에 `Bearer {TOKEN}` 형태로 담아 전송합니다.
    3. 백엔드의 `authMiddleware`는 해당 토큰의 유효성을 검증하고, 검증이 완료되면 요청 객체(`req`)에 사용자 정보를 추가하여 다음 로직으로 전달합니다.
- **구현 코드 (`middleware/authMiddleware.js`)**:
    
    ```
    // ... (JWT 토큰 추출 및 검증 로직)
    const decoded = jwt.verify(token, process.env.JWT_SECRET);
    req.user = decoded; // 요청 객체에 사용자 정보 주입
    next();
    // ...
    
    ```
    

### 3.2. 사용자 관리 (`/api/users`)

- **`POST /register`**: 회원가입. 사용자 비밀번호는 `bcrypt` 라이브러리를 통해 **해시 암호화**되어 DB에 저장됩니다.
- **`POST /login`**: 로그인. 비밀번호 일치 여부를 `bcrypt.compare`로 확인하고, 성공 시 JWT 토큰을 발급합니다.
- **`GET /me`**: 내 정보 조회. `authMiddleware`를 통과해야만 접근 가능한 API로, 토큰에 담긴 사용자 정보를 반환합니다.

### 3.3. TTS 변환 (`/api/tts`)

- **`POST /convert`**: 텍스트 음성 변환 요청 처리.
    1. `authMiddleware`로 사용자를 인증합니다.
    2. `axios`를 사용하여 **AI 서버(`http://localhost:8000/synthesize`)** 에 텍스트와 모델 정보를 담아 POST 요청을 보냅니다.
    3. AI 서버로부터 음성 파일명과 재생 시간 등을 응답받습니다.
    4. 변환 결과를 `OutputVoice` 테이블에 저장합니다.
    5. 프론트엔드에 최종 파일 URL과 함께 성공 응답을 보냅니다.
- **구현 코드 (`routes/tts.js`)**:
    
    ```
    // ...
    // AI 서버와 통신
    const aiResponse = await axios.post(AI_SERVER_URL, {
        text: text,
        speaker_wav: modelId, // AI 모델이 요구하는 파라미터명
        user_id: userId
    });
    // ...
    const fileUrl = `${req.protocol}://${req.get('host')}/storage/${filename}`;
    
    // DB에 결과 기록
    await db.query(
        'INSERT INTO OutputVoice (userId, modelId, text, fileUrl) VALUES (?, ?, ?, ?)',
        [userId, null, text, fileUrl]
    );
    // ...
    
    ```
    

### 3.4. 음성 모델 관리 (`/api/models`)

- **`POST /custom`**: 커스텀 모델 생성을 위한 음성 파일 업로드.
    1. `authMiddleware`로 사용자를 인증합니다.
    2. `multer` 미들웨어를 사용하여 `voiceSample`이라는 필드로 전송된 음성 파일을 서버의 `uploads/voices/` 경로에 저장합니다.
    3. 저장된 파일의 경로를 응답으로 반환하여, 추후 이 경로를 AI 서버에 전달해 임베딩 추출 작업을 수행하게 됩니다.
- **구현 코드 (`routes/models.js`)**:
    
    ```
    // ... (multer storage 설정: 파일 저장 경로 및 파일명 규칙 정의)
    const upload = multer({ storage: storage });
    
    router.post(
        '/custom',
        authMiddleware,
        upload.single('voiceSample'), // 'voiceSample' 필드의 단일 파일 처리
        async (req, res) => {
            // ...
            const filePath = req.file.path; // 저장된 파일의 경로
            res.status(201).json({
                message: '음성 파일이 성공적으로 업로드되었습니다.',
                filePath: filePath
            });
        }
    );
    // ...
    
    ```
    

### 3.5. 변환 기록 관리 (`/api/history`)

- **`GET /`**: 현재 로그인된 사용자의 모든 음성 변환 기록을 조회합니다.
    - `authMiddleware`를 통해 얻은 `req.user.id`를 사용하여 `OutputVoice` 테이블에서 해당 사용자의 기록만 조회하여 최신순으로 반환합니다.

## 4. 시스템 연동 방안

### 4.1. 프론트엔드 연동

- **CORS**: `cors` 라이브러리를 사용하여 모든 도메인에서의 요청을 허용하도록 설정되어 있어, 개발 환경에서 프론트엔드 서버(e.g., `localhost:3000`)와의 통신이 원활합니다.
- **정적 파일 제공**: `express.static` 미들웨어를 사용하여 AI가 생성한 음성 파일을 `/storage` 경로를 통해 제공합니다. 프론트엔드는 이 URL을 통해 음성을 직접 재생하거나 다운로드할 수 있습니다. (`http://localhost:3001/storage/파일명.wav`)

### 4.2. AI 모델 연동

- 백엔드와 AI 서버는 **REST API**를 통해 통신합니다.
- `axios` 라이브러리를 사용하여 비동기 HTTP 요청을 보내며, AI 서버의 응답 지연이나 오류 발생에 대비한 예외 처리가 구현되어 있습니다. (e.g., `try-catch`, 연결 불가 시 503 에러 응답)

## 5. 결론 및 향후 개선 과제

### 5.1. 개발 완료 내용 요약

- Node.js(Express) 기반의 안정적인 RESTful API 서버를 구축했습니다.
- JWT를 활용한 안전한 사용자 인증 및 인가 시스템을 구현했습니다.
- TTS 변환, 커스텀 모델 파일 업로드, 기록 관리 등 핵심 비즈니스 로직을 모두 구현하고 AI 서버와의 연동을 완료했습니다.

### 5.2. 향후 개선 과제

- **보안 강화**: HTTPS 적용, API 요청 속도 제한(Rate Limiting) 등을 도입하여 보안을 강화할 수 있습니다.
- **성능 최적화**: DB 쿼리 최적화, 자주 사용되는 데이터에 대한 캐싱(e.g., Redis) 도입을 고려할 수 있습니다.
- **배포 자동화**: CI/CD 파이프라인을 구축하여 테스트 및 배포 과정을 자동화할 수 있습니다.