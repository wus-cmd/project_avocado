프로젝트_아보카도(Avocado)_기획서_250911(수정본)

---

# 프로젝트명: 아보카도 (Avocado)

**AI Voice Communication Development Tool**

---
## 1. 프로젝트 개요

### 1.1 한줄 설명

발화가 어려운 사용자를 위한 AI 기반 텍스트-음성 변환 및 커스텀 음성 모델 생성 서비스

### 1.2 문제 정의

* **현재 문제**: 발음이나 발화가 어려운 사람들은 일상적인 대화 및 자기 표현에 제약이 있음. 기존 TTS는 기성 목소리만 제공되어 개인적 친밀감 부족.
* **해결 방법**: 사용자가 입력한 텍스트를 다양한 AI 음성 모델로 변환, 나아가 본인 음성을 기반으로 한 개인 맞춤형 음성 모델을 제작해 자연스러운 소통을 가능하게 함.
* **대상 사용자**: 발화 장애가 있는 사용자, 발음 교정이 필요한 학습자, 그리고 자신의 목소리 톤·스타일을 반영해 대화하고 싶은 일반 사용자.

---

## 2. 주요 기능

**기능 1: 텍스트-음성 변환 (TTS)**

* **설명**: 사용자가 입력한 텍스트를 AI 음성으로 변환
* **세부 기능**:
    * 텍스트 입력
    * 3개의 기본 음성 모델 또는 커스텀 모델 중 선택
    * 변환된 음성 재생 및 다운로드/이메일 전송
* **화면**: 로그인 > 메인 화면 > 텍스트 입력 + 모델 선택 > 결과 확인

**기능 2: 커스텀 음성 모델 제작**

* **설명**: 사용자가 3분 이상의 음성 파일을 업로드하여 자신의 음색, 톤 등 고유한 특징을 추출한 개인화 음성 모델 생성
* **세부 기능**:
    * 고품질 녹음을 위한 가이드 제공
    * 사용자 음성 파일 업로드 (`.wav`, `.mp3`)
    * AI가 음성 특징을 추출하여 **'스피커 임베딩' 생성**
    * “내 목소리 버전” 모델 저장 및 이후 변환에 활용
* **화면**: 메인 화면 > 내 음성 모델 탭 > **음성 파일 업로드 > 임베딩 추출 진행** > 결과 확인

**기능 3: 음성 결과 관리**

* **설명**: 변환된 음성을 사용자가 쉽게 활용할 수 있게 제공
* **세부 기능**:
    * 결과 음성 파일 재생
    * 다운로드
    * 이메일 전송 선택 가능
* **화면**: 결과 확인 화면 > 저장/전송 옵션

---

## 3. 기술 구현 계획

### 3.1 기술 스택

* **프론트엔드**: React (사용자 친화적 UI/UX 구성)
* **백엔드**: Node.js + Express (API 서버, 유연한 확장성)
* **데이터베이스**: **MySQL**
* **AI 모델**: Python, PyTorch, **Coqui XTTS**

### 3.2 데이터 구조

**사용자 (User)**

* id: 고유번호
* pw: 비밀번호
* email: 이메일
* name: 이름
* age: 나이
* gender: 성별
* customVoiceId: 커스텀 음성 모델 ID (옵션)

**음성 모델 (VoiceModel)**

* id: 고유번호
* type: 기본/커스텀
* name: 모델명
* features: 성별, 톤, 어조 정보
* createdBy: 사용자 ID (커스텀일 경우)

**변환 결과 (OutputVoice)**

* id: 고유번호
* userId: 사용자 ID
* text: 입력 텍스트
* modelId: 사용된 음성 모델
* fileUrl: 결과 음성 파일 저장 경로
* createdAt: 생성 일시

### 3.3 API 설계

**\[사용자]**

* `POST /api/register` - 회원가입
* `POST /api/login` - 로그인
* `GET /api/user/:id` - 사용자 정보 조회

**\[음성 모델]**

* `GET /api/models` - 기본 모델 조회
* `POST /api/models/custom` - 커스텀 모델 생성 (**음성 파일 업로드 기반**)

**\[텍스트-음성 변환]**

* `POST /api/convert` - 텍스트 입력 → 음성 변환
* `GET /api/output/:id` - 변환 결과 조회

---

## 4. 화면 구성

### 4.1 화면 흐름

로그인 화면 → 메인 화면 (탭 구조)

* 텍스트 입력 + 모델 선택 탭
* 결과 확인 탭
* 내 음성 모델 탭 (커스텀)
* 설정 탭

### 4.2 주요 화면 설명

**메인 화면**

* 상단: 로고, 사용자 메뉴
* 중앙: 텍스트 입력창, 모델 선택 드롭다운, 변환 버튼
* 하단: 변환 결과 요약

**커스텀 음성 모델 화면**

* **안내 문구**: “고품질 모델을 위해 3분 이상의 음성 파일을 업로드해주세요.”
* **음성 파일 업로드 인터페이스**
* **임베딩 추출 진행 상태 표시**
* 결과 저장 및 미리듣기

---

## 5. 개발 일정

**주차별 계획**

* 1주차: 기획 완료, 개발환경 세팅
* 2주차: AI 모델 프로토타입 구축 (기본 TTS)
* 3주차: 백엔드 API 개발, DB 설계
* 4주차: 프론트엔드 화면 구현
* 5주차: 커스텀 모델 학습 기능 개발
* 6주차: 기능 연동 및 테스트
* 7주차: 버그 수정 및 발표 준비

**팀원 역할**

* 김나현: AI 모델링 및 기획
* 변정우: 백엔드 개발 및 스케줄 관리
* 나은비: 프론트엔드 개발 및 디자인

---

## 6. 예상 어려움과 해결 방안

* **문제 1**: 사용자 발음이 불명확할 때 커스텀 학습 정확도 저하
    * **해결**: **Coqui XTTS의 '스피커 임베딩' 방식을 채택하여 사용자의 발음이 아닌 고유한 음색과 톤만 추출. 이를 통해 원본 모델의 깨끗한 발음은 유지하면서 사용자의 목소리 톤만 적용하여 문제를 근본적으로 해결**.
* **문제 2**: 실시간 변환 속도 지연
    * **해결**: 캐싱 및 사전 모델 로딩 최적화
* **문제 3**: 서버 비용 증가
    * **해결**: 초기엔 무료 티어 클라우드 + 필요 시 GPU 서버 확장

---

## 7. 향후 확장 가능성

* 실시간 음성 변환 (STT → 변환 → 즉시 발화)
* 다국어 지원 (영어, 일본어, 중국어 등)
* 교육/연구용 발음 교정 툴과 연동
* 감정(Tone) 선택 기능 (기쁨, 차분, 전문적 등)