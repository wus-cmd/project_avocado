---

# **프로젝트_아보카도(Avocado)_기획서**

**AI Voice Communication Development Tool**

---

## 1. 프로젝트 개요

### 1.1 한줄 설명

발화가 어려운 사용자를 위한 AI 기반 텍스트-음성 변환 및 커스텀 음성 모델 생성 서비스

### 1.2 문제 정의

* **현재 문제**: 발음이나 발화가 어려운 사람들은 일상적인 대화 및 자기 표현에 제약이 있음. 기존 TTS는 기성 목소리만 제공되어 개인적 친밀감 부족.
* **해결 방법**: 사용자가 입력한 텍스트를 다양한 AI 음성 모델로 변환, 나아가 본인 음성을 기반으로 한 개인 맞춤형 음성 모델을 제작해 자연스러운 소통을 가능하게 함.
* **대상 사용자**: 발화 장애가 있는 사용자, 발음 교정이 필요한 학습자, 그리고 자신의 목소리 톤·스타일을 반영해 대화하고 싶은 일반 사용자.

---

## 2. 주요 기능

**기능 1: 텍스트-음성 변환 (TTS)**

* **설명**: 사용자가 입력한 텍스트를 AI 음성으로 변환
* **세부 기능**:

  * 텍스트 입력
  * **남성, 여성, 캐릭터** 3개의 기본 음성 모델 또는 커스텀 모델 중 선택
  * 변환된 음성 재생 및 다운로드(WAV/MP3)/이메일 전송
* **화면**: 로그인 > 메인 화면 > 텍스트 입력 + 모델 선택 > 결과 확인

**기능 2: 커스텀 음성 모델 제작**

* **설명**: 사용자가 1~2분의 음성 파일을 업로드하여 자신의 음색, 톤 등 고유한 특징을 추출한 개인화 음성 모델 생성
* **세부 기능**:

  * 고품질 녹음을 위한 가이드 제공
  * 사용자 음성 파일 업로드 (`.wav`, `.mp3`)
  * AI가 음성 특징을 추출하여 **'스피커 임베딩' 생성**
  * “내 목소리 버전” 모델 저장 및 이후 변환에 활용
* **화면**: 메인 화면 > 내 음성 모델 탭 > **음성 파일 업로드 > 임베딩 추출 진행** > 결과 확인

**기능 3: 음성 결과 관리**

* **설명**: 변환된 음성을 사용자가 쉽게 활용할 수 있게 제공
* **세부 기능**:

  * 결과 음성 파일 재생
  * 다운로드
  * 이메일 전송 선택 가능
* **화면**: 결과 확인 화면 > 저장/전송 옵션

---

## 3. 기술 구현 계획

### 3.1 기술 스택

* **프론트엔드**: **React 19.1.1** 기반, **Vite 7.1.2**를 빌드 도구로 사용. **Tailwind CSS**로 스타일링하며, **Fetch API**로 서버와 통신.
* **백엔드**: **Node.js + Express** 기반 API 서버. **JWT**를 통한 사용자 인증, `bcrypt`를 이용한 비밀번호 암호화, `multer`를 통한 파일 업로드 처리.
* **데이터베이스**: **MySQL**
* **AI 모델**: **Python**, **PyTorch** 기반 **Coqui XTTS v2** 모델 활용. API 서버는 **FastAPI**로 구축.

### 3.2 데이터 구조

**사용자 (User)**

* `id`: 고유번호 (PK)
* `email`: 이메일 (UNIQUE)
* `pw`: 비밀번호 (해시 암호화)
* `name`: 이름
* `age`, `gender`: 나이, 성별
* `createdAt`: 가입 일시

**음성 모델 (VoiceModel)**

* `id`: 고유번호 (PK)
* `userId`: 사용자 ID (FK, 커스텀 모델의 경우)
* `type`: 모델 타입 (기본/커스텀)
* `name`: 모델명
* `embedding_vector`: AI가 사용하는 음성 특징 벡터

**변환 결과 (OutputVoice)**

* `id`: 고유번호 (PK)
* `userId`: 사용자 ID (FK)
* `modelId`: 사용된 음성 모델 ID (FK)
* `text`: 입력 텍스트
* `fileUrl`: 결과 음성 파일 저장 경로
* `createdAt`: 생성 일시

### 3.3 API 설계

**[인증]**

* `POST /api/register` - 회원가입
* `POST /api/login` - 로그인
* `POST /api/auth/reset-password` - 비밀번호 재설정
* `GET /api/users/me` - 내 정보 조회 (인증 필요)

**[음성 변환 및 기록]**

* `POST /api/convert` - 텍스트 입력 → 음성 변환 (인증 필요)
* `GET /api/history` - 현재 사용자의 변환 기록 전체 조회 (인증 필요)

**[커스텀 음성 모델]**

* `POST /api/models/custom` - 커스텀 모델 생성을 위한 음성 파일 업로드 (인증 필요)

---

## 4. 화면 구성

### 4.1 화면 흐름

로그인 화면 → 메인 화면 (탭 구조)

* 텍스트 입력 + 모델 선택 탭
* 결과 확인 탭
* 내 음성 모델 탭 (커스텀)
* 설정 탭

### 4.2 주요 화면 설명

**메인 화면**

* 상단: 로고, 사용자 메뉴
* 중앙: 텍스트 입력창, 모델 선택 드롭다운, 변환 버튼
* 하단: 변환 결과 요약 (커스텀 오디오 플레이어)

**커스텀 음성 모델 화면**

* **안내 문구**: “고품질 모델을 위해 3분 이상의 음성 파일을 업로드해주세요.”
* **음성 파일 업로드 인터페이스**
* **임베딩 추출 진행 상태 표시**
* 결과 저장 및 미리듣기

---

## 5. 개발 일정 및 역할

**주차별 계획**

* 1주차: 기획 완료, 개발환경 세팅
* 2주차: AI 모델 프로토타입 구축 (기본 TTS)
* 3주차: 백엔드 API 개발, DB 설계
* 4주차: 프론트엔드 화면 구현
* 5주차: 커스텀 모델 학습 기능 개발
* 6주차: 기능 연동 및 테스트
* 7주차: 버그 수정 및 발표 준비

**팀원 역할**

* 김나현: AI 모델링 및 기획
* 변정우: 백엔드 개발 및 스케줄 관리
* 나은비: 프론트엔드 개발 및 디자인

---

## 6. 예상 어려움과 해결 방안

* **문제 1**: 사용자 발음이 불명확할 때 커스텀 학습 정확도 저하

  * **해결**: **Coqui XTTS의 '스피커 임베딩' 방식을 채택하여 사용자의 발음이 아닌 고유한 음색과 톤만 추출. 이를 통해 원본 모델의 깨끗한 발음은 유지하면서 사용자의 목소리 톤만 적용하여 문제를 근본적으로 해결**.
* **문제 2**: 실시간 변환 속도 지연

  * **해결**: 캐싱 및 사전 모델 로딩 최적화
* **문제 3**: 서버 비용 증가

  * **해결**: 초기엔 무료 티어 클라우드 + 필요 시 GPU 서버 확장

---
